retrieval:
  embedder_model: sentence-transformers/all-MiniLM-L6-v2
  normalize: true
  top_k: 12
  faiss_index: data/index/handbook.index
  store_json: data/index/docstore.json
  hybrid_alpha: 0.6

chunk:
  max_chars: 1200
  overlap: 150

reranker:
  model: cross-encoder/ms-marco-MiniLM-L-6-v2
  top_n: 30

eval:
  # File with evaluation questions; see template below.
  questions_file: configs/eval_questions.yaml

  # K used for metrics. You can override per run via CLI args if needed.
  k: 12

  # Promotion thresholds (all must pass):
  pass_thresholds:
    retrieval_hit_rate: 0.70     # fraction of queries with >=1 relevant in top-k
    precision_at_k: 0.35         # macro-avg (#relevant@k / k)
    mrr: 0.45                    # mean reciprocal rank of first relevant

mlflow:
  tracking_uri: "file:./mlruns"
  experiment: "EKA_RAG"
  registered_model: "EKA_RAG_Index"   # used only for pointer naming/tags

agent:
  auto_actions: false
